{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC-IJfoeK7hD"
      },
      "source": [
        "# **üóÉÔ∏è Data Lab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj-wgtpcBmuN"
      },
      "source": [
        "Useful dataset: [Fruits dataset](https://drive.google.com/file/d/1Jn15Qra1NldKC6ELVTTFWrqZ5OJdK5pL/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxrrSG1voiSd"
      },
      "source": [
        "## Generate samples üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uTPPONJHzBR5"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "# ============\n",
        "# Parameters\n",
        "# ============\n",
        "\n",
        "n_samples = 300 # @param {type:\"integer\"}\n",
        "type_dataset = \"noisy_moons\" # @param [\"noisy_circles\", \"noisy_moons\", \"blobs\", \"no_structure\", \"anisotropic\", \"varied_var\"]\n",
        "noise = 0.19 # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "angle_aniso = 110 # @param {type:\"slider\", min:0, max:180, step:10}\n",
        "deg_reg = 3 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "random_state = 1 # @param {type:\"integer\"}\n",
        "return_classes = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "\n",
        "# ============\n",
        "# Generate datasets. We choose the size big enough to see the scalability\n",
        "# of the algorithms, but not too big to avoid too long running times\n",
        "# ============\n",
        "\n",
        "if type_dataset == \"noisy_circles\":\n",
        "  X, y = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"noisy_moons\":\n",
        "  X, y = datasets.make_moons(n_samples=n_samples, noise=noise, random_state=random_state)\n",
        "\n",
        "elif type_dataset == \"blobs\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, cluster_std=noise*5, random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"no_structure\":\n",
        "  X = np.random.rand(n_samples, 2)\n",
        "\n",
        "elif type_dataset == \"anisotropic\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
        "  t = np.tan(np.radians(angle_aniso))\n",
        "  transformation = np.array(((1, t), (0, 1))).T\n",
        "  X = np.dot(X, transformation)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "elif type_dataset == \"varied_var\":\n",
        "  X, y = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
        "  X += np.random.rand(n_samples, 2)*noise*X.min()\n",
        "\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "if return_classes:\n",
        "  ax.scatter(X[:, 0], X[:, 1], c = y, edgecolors='k', cmap='Paired')\n",
        "else:\n",
        "  ax.scatter(X[:, 0], X[:, 1], edgecolors='k')\n",
        "\n",
        "print (\"\\nData shape: {0} \\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXWye_RQo3r3"
      },
      "source": [
        "## Load a dataset üìë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "YP61e7ngtFAE",
        "outputId": "80d882c8-7e49-4868-94bc-081d25fdd6b6"
      },
      "outputs": [],
      "source": [
        "# @markdown ---\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown ### üîº Upload your file (first)\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ### Enter path to **.csv* file:\n",
        "file_path = \"\" # @param {type:\"string\"}\n",
        "delimiter = \",\" # @param {type:\"string\"}\n",
        "\n",
        "var_h = \"\" # @param {type:\"string\"}\n",
        "var_v = \"\" # @param {type:\"string\"}\n",
        "hue   = \"\" # @param {type:\"string\"}\n",
        "normalization = \"None\" # @param [\"MinMax [0,1]\", \"MinMax [-1,1]\", \"Z-Score\", \"None\"]\n",
        "Load_all_data = False # @param {type:\"boolean\"}\n",
        "Remove_missing = True # @param {type:\"boolean\"}\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data = pd.read_csv(file_path, delimiter=delimiter)\n",
        "\n",
        "if Remove_missing:\n",
        "  data = data.dropna()\n",
        "\n",
        "if not Load_all_data:\n",
        "  X = np.c_[np.array(data[var_h]), np.array(data[var_v])]\n",
        "else:\n",
        "  X = np.array(data)\n",
        "\n",
        "y = np.array(data[hue]) if hue != \"\" else None\n",
        "\n",
        "if   normalization == \"MinMax [0,1]\":\n",
        "  X = MinMaxScaler(feature_range=( 0,1)).fit_transform(X)\n",
        "elif normalization == \"MinMax [-1,1]\":\n",
        "  X = MinMaxScaler(feature_range=(-1,1)).fit_transform(X)\n",
        "elif normalization == \"Z-Score\":\n",
        "  X = StandardScaler().fit_transform(X)\n",
        "\n",
        "\n",
        "if not Load_all_data:\n",
        "  data[var_h], data[var_v] = X[:, 0], X[:, 1]\n",
        "else:\n",
        "  for i in range(len(data.columns)):\n",
        "    data.iloc[:, i] = X[:, i]\n",
        "\n",
        "\n",
        "_, ax = plt.subplots (figsize=(5,4))\n",
        "# ax.scatter(X[:, 0], X[:, 1], c=y, cmap='Paired', edgecolors='k')\n",
        "sns.scatterplot(ax=ax,data=data,x=var_h,y=var_v, hue=hue if hue != \"\" else None, palette='colorblind')\n",
        "print (\"\\nData Loaded! ‚úÖ\")\n",
        "print (\" - Shape: {0}\\n\".format(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJbFYZLULD_u"
      },
      "source": [
        "# **üìã Model Lab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe_aDliK0FKf"
      },
      "outputs": [],
      "source": [
        "from sklearn import cluster, mixture\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# @markdown \\\n",
        "\n",
        "model = \"SpectralClustering\" # @param [\"Kmeans\", \"MiniBatchKMeans\", \"MeanShift\", \"Ward\", \"SpectralClustering\", \"DBSCAN\", \"OPTICS\", \"AgglomerativeClustering\", \"GaussianMixture\"]\n",
        "n_clusters = 2 # @param {type:\"integer\"}\n",
        "random_state = 4 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown \\\n",
        "# @markdown ### ‚úèÔ∏è Aditional Params\n",
        "# @markdown \\\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è K-Means\n",
        "# @markdown \\\n",
        "\n",
        "kmeans_init_km = \"random\" # @param [\"k-means++\", \"random\"]\n",
        "# metric_km = \"euclidean\" # @param [\"euclidean\", \"cityblock\", \"cosine\", \"l1\", \"l2\", \"chebyshev\", \"mahalanobis\"]\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è MeanShift\n",
        "# @markdown \\\n",
        "\n",
        "bandwidth = 0.1 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Ward\n",
        "# @markdown \\\n",
        "\n",
        "n_neighbors_wd = 2 # @param {type:\"integer\"}\n",
        "metric_wd = \"euclidean\" # @param [\"euclidean\", \"cityblock\", \"cosine\", \"l1\", \"l2\", \"chebyshev\", \"mahalanobis\"]\n",
        "\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Spectral Clustering\n",
        "# @markdown \\\n",
        "\n",
        "eigen_solver = \"arpack\" # @param [\"arpack\", \"lobpcg\", \"amg\"]\n",
        "affinity = \"nearest_neighbors\" # @param [\"nearest_neighbors\", \"rbf\"]\n",
        "\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è DBSCAN\n",
        "# @markdown \\\n",
        "\n",
        "eps = 0.1 # @param {type:\"number\"}\n",
        "metric_db = \"euclidean\" # @param [\"euclidean\", \"cityblock\", \"cosine\", \"l1\", \"l2\", \"chebyshev\", \"mahalanobis\"]\n",
        "\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Agglomerative Clustering\n",
        "# @markdown \\\n",
        "\n",
        "n_neighbors_ad = 2 # @param {type:\"integer\"}\n",
        "metric_ad = \"euclidean\" # @param [\"euclidean\", \"cityblock\", \"cosine\", \"l1\", \"l2\", \"chebyshev\", \"mahalanobis\"]\n",
        "\n",
        "# @markdown \\\n",
        "# @markdown #### ‚öôÔ∏è Gaussian Mixture\n",
        "# @markdown \\\n",
        "\n",
        "covariance_type_gm = \"full\" # @param ['full', 'tied', 'diag', 'spherical']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "if model == \"Kmeans\":\n",
        "  algo = cluster.KMeans(n_clusters=n_clusters, init=kmeans_init_km,  random_state=random_state)\n",
        "\n",
        "elif model == \"MiniBatchKMeans\":\n",
        "  algo = cluster.MiniBatchKMeans(n_clusters=n_clusters, init=kmeans_init_km, random_state=random_state)\n",
        "\n",
        "elif model == \"MeanShift\":\n",
        "  algo = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True, random_state=random_state)\n",
        "\n",
        "elif model == \"Ward\":\n",
        "  connectivity = kneighbors_graph(X, n_neighbors=n_neighbors_wd, include_self=False)\n",
        "  algo = cluster.AgglomerativeClustering(n_clusters=n_clusters, linkage=\"ward\", \\\n",
        "                                         metric=metric_wd, connectivity=connectivity)\n",
        "\n",
        "elif model == \"SpectralClustering\":\n",
        "  algo = cluster.SpectralClustering(n_clusters=n_clusters, \\\n",
        "                                    eigen_solver=eigen_solver, \\\n",
        "                                    affinity=\"nearest_neighbors\", \\\n",
        "                                    random_state=random_state)\n",
        "\n",
        "elif model == \"DBSCAN\":\n",
        "  algo = cluster.DBSCAN(eps=eps, metric=metric_db)\n",
        "\n",
        "elif model == \"AgglomerativeClustering\":\n",
        "  connectivity = kneighbors_graph(X, n_neighbors=n_neighbors_ad, include_self=False)\n",
        "  algo = cluster.AgglomerativeClustering(linkage=\"average\", metric=metric_ad, \\\n",
        "                                          n_clusters=n_clusters, \\\n",
        "                                          connectivity=connectivity)\n",
        "\n",
        "elif model == \"GaussianMixture\":\n",
        "  algo = mixture.GaussianMixture(n_components=n_clusters, covariance_type=covariance_type_gm, random_state=random_state)\n",
        "\n",
        "\n",
        "\n",
        "print (\"\\nModel {0} is ready!\\n\".format(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRSkfgspLKO2"
      },
      "source": [
        "# **ü§ñ Run training!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yZZKIePgDV7B"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle, islice\n",
        "\n",
        "# @markdown ### Start now ü¶æ\n",
        "# @markdown \\\n",
        "\n",
        "\n",
        "algo.fit(X)\n",
        "\n",
        "if hasattr(algo, \"labels_\"):\n",
        "    pred = algo.labels_.astype(int)\n",
        "else:\n",
        "    pred = algo.predict(X)\n",
        "\n",
        "_, ax = plt.subplots(figsize=(5,4))\n",
        "ax.set_title(\"{0}\".format(model))\n",
        "\n",
        "print (\"\\nTraining done! ‚úÖ\")\n",
        "\n",
        "colors = np.array(list(islice(cycle([\"#377eb8\", \"#ff7f00\", \"#4daf4a\", \"#f781bf\", \"#a65628\", \\\n",
        "                                     \"#984ea3\", \"#999999\", \"#e41a1c\", \"#dede00\", \"#000000\"]), int(max(pred) + 1),)))\n",
        "\n",
        "ax.scatter(X[:, 0], X[:, 1], c=colors[pred], edgecolors='k')\n",
        "print (\"Plots... \\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JC-IJfoeK7hD",
        "DxrrSG1voiSd",
        "pXWye_RQo3r3",
        "eJbFYZLULD_u",
        "rRSkfgspLKO2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
